---
title: "B. Using R to Understand Bioinformatic Results"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{B. Using R to Understand Bioinformatic Results}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(collapse = TRUE)
library(stats)
library(graphics)
```

This workshop introduces *R* as an essential tool in exploratory
analysis of bioinformatic data. No previous experience with *R* is
required. We start with a very short introduction to *R*, mentioning
vectors, functions, and the `data.frame` for representing tabular
data. We explore some essential data management tasks, for instance
summarizing cell types and plotting a 'UMAP' in a single-cell RNASeq
experiment. We adopt the 'tidy' paradigm, using the [dplyr][] package
for data management and [ggplot2][] for data visualization. The
workshop concludes with a short tour of approaches to enhance
reproducible research in our day-to-day work.

# Essential _R_

A simple calculator

```{r}
1 + 1
```

'Vectors' as building blocks

```{r}
c(1, 2, 3)
c("January", "February", "March")
c(TRUE, FALSE)
```

Variables, missing values and 'factors'

```{r}
age <- c(27, NA, 32, 29)
gender <- factor(
    c("Female", "Male", "Non-binary", NA),
    levels = c("Female", "Male", "Non-binary")
)
```

Data structures to coordinate related vectors -- the `data.frame`

```{r}
df <- data.frame(
    age = c(27, NA, 32, 29),
    gender = gender
)
df
```

Key opererations on `data.frame`

- `df[1:3, c("gender", "age")]` -- subset on rows and columns
- `df[["age"]]`, `df$age` -- select columns

Functions

```{r}
rnorm(5)        # 5 random normal deviates
x <- rnorm(100) # 100 random normal deviates
hist(x)         # histogram, approximately normal
plot(density(x)) # a little more sophisticated?
```

'Vectorized' operations, e.g., element-wise addition without an
explicit 'for' loop


```{r}
y <- x + rnorm(100)
plot(y ~ x)
fit <- lm(y ~ x)
fit         # an R 'object' containing information about the
            # regression of y on x
abline(fit) # plot points and fitted regression line
anova(fit)  # statistical summary of linear regression
```

Write your own functions

```{r}
hello <- function(who) {
    paste("hello", who, "with", nchar(who), "letters in your name")
}
hello("Martin")
```

Iterate, usually with `lapply()` although `for()` is
available

```{r}
names <- c("Martin", "Thomas")
lapply(names, hello)
```

# Packages

Extend functionality of base _R_. Can be part of the 'base' distribution...

```{r}
## iterate over the numbers 1 through 8, 'sleeping' for 1 second
## each. Takes about 8 seconds...
system.time({
    lapply(1:8, function(i) Sys.sleep(1))
})

## sleep in parallel -- takes only 2 seconds
library(parallel)
cl <- makeCluster(4) # cluster of 4 workers
system.time({
    parLapply(cl, 1:8, function(i) Sys.sleep(1))
})
```

## Tidyverse

The [dplyr][] package introduces the 'tidyverse'

```{r, message = FALSE}
library(dplyr)
```

A 'tibble' is like a 'data.frame', but more user-friendly

```{r}
tbl <- tibble(
    x = rnorm(100),
    y = x + rnorm(100)
)

## e.g., only displays the first 10 rows
tbl
```

The tidyverse makes use of 'pipes' `|>` (the older syntax is `%>%`). A
pipe takes the left-hand side and pass through to the right-hand
side. Key [dplyr][] 'verbs' can be piped together

- `tibble()` -- representation of a `data.frame`, with better display
  of long and wide data frames. `tribble()` constructs a tibble in a
  way that makes the relationship between data across rows more
  transparent.
- `glimpse()` -- providing a quick look into the columns and data in
  the tibble by transposing the tibble and display each 'column' on a
  single line.
- `select()` -- column selection.
- `filter()`, `slice()` -- row selection.
- `pull()` -- extract a single column as a vector.
- `mutate()` -- column transformation.
- `count()` -- count occurences in one or more columns.
- `arrange()` -- order rows by values in one or more columns.
- `distinct()` -- reduce a tibble to only unique rows.
- `group_by()` -- perform computations on groups defined by one or
  several columns.
- `summarize()` -- calculate summary statstics for groups.
- `left_join()`, `right_join()`, `inner_join()` -- merge two tibbles
  based on shared columns, preserving all rows in the first
  (`left_join()`) or second (`right_join()`) or both (`inner_join()`)
  tibble.

```{r}
tbl |>
    ## e.g., just rows with non-negative values of x and y
    filter(x > 0, y > 0) |>
    ## add a column
    mutate(distance_from_origin = sqrt(x^2 + y^2))
```

A 'classic' built-in data set -- Motor Trend 'cars' from
1974... 'tidyverse' eschews rownames, so make these a column. Use
`group_by()` to summarize by group (`cyl`). `n()` is a function from
dplyr that returns the number of records in a group.

```{r}
mtcars_tbl <-
    mtcars |>
    as_tibble(rownames = "model") |>
    mutate(cyl = factor(cyl))
mtcars_tbl

mtcars_tbl |>
    group_by(cyl) |>
    summarize(
        n = n(),
        mean_mpg = mean(mpg, na.rm = TRUE),
        var_mpg = var(mpg, na.rm = TRUE)
    )
```

## Visualization

Another example of a contributed package is [ggplot2][] for visualization

```{r, message = FALSE}
library(ggplot2)
ggplot(tbl) +
    aes(x, y) +                # use 'x' and 'y' columns for plotting...
    geom_point() +             # ...plot points...
    geom_smooth(method = "lm") # ...linear regresion
```

Check out [plotly][], especially for interactive visualization (e.g.,
'tooltips' when mousing over points, or dragging to subset and zoom
in)

```{r, message = FALSE}
library(plotly)
plt <-
    ggplot(mtcars_tbl) +
    aes(x = cyl, y = mpg, text = model) +
    geom_jitter(width = .25) +
    geom_boxplot()
ggplotly(plt)
```

## Where do Packages Come From?

- [CRAN][]: *C*omprehensive *R* *A*rchive *N*etwork. More than 18,000
  packages. Some help from [CRAN Task Views][] in identifying relevant
  packages.

- [Bioconductor][]: More than 2100 packages relevant to
  high-throughput genomic analysis. _Vignettes_ are an important part
  of _Bioconductor_ packages.
  
Install packages once per _R_ installation, using
`BiocManager::install(<package-name>)` (CRAN or Bioconductor)

What about GitHub? Packages haven't been checked by a formal system,
so may have incomplete code, documentation, dependencies on other
packages, etc. Authors may not yet be committed to long-term
maintenance of their package.

[CRAN]: https://cran.r-project.org/web/packages/available_packages_by_name.html
[CRAN Task Views]: https://cran.r-project.org/web/views/
[Bioconductor]: https://bioconductor.org/packages
[dplyr]: https://cran.r-project.org/package=dplyr
[ggplot2]: https://cran.r-project.org/package=ggplot2
[plotly]: https://cran.r-project.org/package=plotly

## Help & Vignettes

1. Help pages, e.g., `?lm`

2. Vignettes, e.g., 

    ```{r, eval = FALSE}
    vignette(package = "ggplot2")
    vignette("ggplot2-specs", "ggplot2")
    ```

3. Google, StackOverflow, etc...

# Bioinformatics -- scRNA-seq

```{r, eval = FALSE, echo = FALSE}
collection_id <- "c9706a92-0e5f-46c1-96d8-20e42467f287"
db <- cellxgenedp::db()
dataset <-
    cellxgenedp::datasets(db) |>
    filter(collection_id %in% .env$collection_id)
files <-
    left_join(dataset, cellxgenedp::files(db), by = "dataset_id")
h5ad_file <-
    files |>
    dplyr::filter(filetype == "H5AD") |>
    cellxgenedp::files_download(dry.run = FALSE)

h5ad <- zellkonverter::readH5AD(h5ad_file, reader = "R", use_hdf5 = FALSE)

counts <- Matrix::sparseMatrix(
    i = as.vector(rhdf5::h5read(h5ad_file, "/raw/X/indices")) + 1L,
    p = as.vector(rhdf5::h5read(h5ad_file, "/raw/X/indptr")),
    x = as.vector(rhdf5::h5read(h5ad_file, "/raw/X/data"))
)
Matrix::writeMM(counts, "inst/scrnaseq-counts.mtx")

col_data <-
    SingleCellExperiment::colData(h5ad) |>
    as_tibble(rownames = "cell_id")
umap <- SingleCellExperiment::reducedDim(h5ad, "X_umap")
colnames(umap) <- c("UMAP_1", "UMAP_2")
col_data <-
    dplyr::bind_cols(col_data, umap) |>
    select(cell_id, starts_with("UMAP"), everything())
readr::write_csv(col_data, "inst/scrnaseq-cell-data.csv")

row_data <-
    SingleCellExperiment::rowData(h5ad) |>
    as_tibble(rownames = "gene_id") |>
    mutate(
        mean_expression = Matrix::rowMeans(counts),
        mean_log_expression = Matrix::rowMeans(log1p(counts))
    )
readr::write_csv(row_data, "inst/scrnaseq-gene-data.csv")
```

## Cell summary

Read a 'csv' file summarizing infomration about each cell in the
experiment.

```{r, message = FALSE}
## use `file.choose()` or similar for your own data sets
cell_data_csv <- system.file(package = "XM2023", "scrnaseq-cell-data.csv")
cell_data <- readr::read_csv(cell_data_csv)
cell_data |>
    glimpse()
```

Summarize information -- how many donors, what developmental stage,
what ethnicity?

```{r}
cell_data |>
    count(donor_id, development_stage, self_reported_ethnicity)
```

What cell types have been annotated?

```{r}
cell_data |>
    count(cell_type)
```

Cell types for each ethnicity?

```{r}
cell_data |>
    count(self_reported_ethnicity, cell_type) |>
    tidyr::pivot_wider(
               names_from = "self_reported_ethnicity",
               values_from = "n"
           )
```

Reflecting on this -- there is no replication across non-European
ethnicity, so no statistical insights available. Pooled samples
probably require careful treatment in any downstream analysis.

## UMAP visualization

Use the 'UMAP' columns to visualize gene expression

```{r, message = FALSE}
library(ggplot2)
plt <-
    ggplot(cell_data) +
    aes(UMAP_1, UMAP_2, color = cell_type) +
    geom_point(pch = ".")
plt
```

Make this interactive, for mouse-over 'tool tips' and 'brushing' selection

```{r, message = FALSE, warning = FALSE}
library(plotly)
ggplotly(plt) |>
    toWebGL()
```

## Genes

```{r, message = FALSE}
## use `file.choose()` or similar for your own data sets
row_data_csv <- system.file(package = "XM2023", "scrnaseq-gene-data.csv")
row_data <- readr::read_csv(row_data_csv)
row_data |>
    glimpse()
```

Approximately 1/3rd have been flagged to be filtered. All genes are
from humans (`NCBITaxon:9606`) and are of biotype 'gene'.

```{r}
row_data |>
    count(feature_is_filtered, feature_reference, feature_biotype)
```

A simple plot shows the distribution of log-transformed average
expression of each gene

```{r}
row_data |>
    filter(!feature_is_filtered) |>
    ggplot() +
    aes(x = mean_log_expression) +
    geom_histogram()
```

# _Bioconductor_ resources

## Overview

Web site -- <https://bioconductor.org>

- Available packages <https://bioconductor.org/packages>
- Package landing pages & vignettes, e.g.,
  <https://bioconductor.org/packages/scater>

Package installation

- Use CRAN package [BiocManager][]
- _Bioconductor_, CRAN, and github packages

```{r, eval = FALSE}
if (!"BiocManager" %in% rownames(installed.packages()))
    install.packages("BiocManager", repos = "https://cran.R-project.org")
BiocManager::install("GenomicFeatures")
```

Support site -- <https://support.bioconductor.org>

- also
  - slack -- sign up - <https://slack.bioconductor.org/>
  - Bug reports, e.g., `bug.report(package = "GenomicFeatures")`
  - direct email to maintainers `maintainer("GenomicFeatures")`

Source code

- <https://git.bioconductor.org>

  - `git clone https://git.bioconductor.org/packages/GenomicFeatures`

- <https://code.bioconductor.org>

Other resources

- [Orchestrating Single-Cell Analysis with Bioconductor][OSCA]

[BiocManager]: https://cran.r-project.org/package=BiocManager
[OSCA]: https://bioconductor.org/books/release/OSCA/

## Annotations

From `row_data`, we know each Ensembl gene id, but what else can we
learn about these genes?

```{r, message = FALSE}
library(AnnotationHub)
ah <- AnnotationHub()
query(ah, c("EnsDb", "Homo sapiens"))
```

```{r}
ensdb109 <- ah[["AH109606"]]
ensdb109
```

There are a number of 'tables' of data in the EnsDb; check out
`browseVignettes("ensembldb")` for more information.

```{r}
names(listTables(ensdb109))
```

E.g., add information about each unfiltered gene from `row_data`.

- get gene annotations from the EnsDB object

    ```{r}
    gene_annotations <-
        genes(
            ensdb109,
            filter = ~ gene_biotype == "protein_coding",
            return.type = "DataFrame"
        ) |>
        as_tibble()
    ```

- `left_join()` the filtered `row_data` to `gene_annotations` (i.e.,
  keep all rows from the filtered row data, and add columns for
  matching rows from `gene_annotations`)
  
    ```{r}
    row_data |>
        dplyr::filter(!feature_is_filtered) |>
        left_join(gene_annotations)
    ```

Many other annotation resources available, to help place information
about genes into biological context.

# Reproducibility

Packages

- Provide a robust way to document requirements for analysis, and to
  organize complicated analyses into distinct steps.

    ```{r devtools, eval = FALSE}
    devtools::create("MyAnalysis")
    setwd("MyAnalysis")
    usethis::use_vignette("a_data_management", "A. Data management")
    usethis::use_vignette("b_exploratory_visualization", "B. Exploration")
    ```

- I've found [pkgdown][] to be very useful for presenting packages to
  my users. For instance, [material from this workshop][workshop] is
  available through pkgdown.

    ```{r pkgdown, eval = FALSE}
    usethis::use_pkgdown()
    pkgdown::build_site()
    ```

[pkgdown]: https://cran.r-project.org/package=pkgdown
[workshop]: https://mtmorgan.github.io/XM2023

Vignettes

- Explict description of analysis steps (good for the
  bioinformatician), coupled with text and graphics (good for the
  collaboration).

Git

- Incremental 'commits' as analysis progresses.
- Commits allow confident exploration -- the last commit is always
  available to 'start over'.
- Tags allow checkpointing an analysis, e.g., the version of the
  analysis used in the original manuscript submission; the version of
  the analysis associated with the revision and final publciation.

Containers

- A fully reproducible analysis is very challenging to implement --
  specifying software version is not enough, and is not easy for a
  future investigator to re-establish.
- Containers like [docker][] or [singularity][] provide one mechanism
  for creating a 'snapshot' capturing exactly the software used.
- Beware! Complicated containers might result in a fully reproducible
  analysis, but provide little confidence in the robustness of the
  analysis.

[docker]: https://www.docker.com
[singularity]: https://sylabs.io/

# Summary

## More to come...

Tomorrow

- Discover single-cell data sets in the CELLxGENE data portal
- Download and import data sets as 'Seurat' or 'SingleCellExperiment'
  objects.
- Coordinate cell annotation and gene annotation

## Session information

This document was produced with the following *R* software:

```{r session_info}
sessionInfo()
```

```{r include = FALSE}
## clean up .GlobalEnv at end of vignette
rm(list = ls(envir = .GlobalEnv, all.names = TRUE), envir = .GlobalEnv)
```
